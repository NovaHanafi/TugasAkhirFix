{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o94YmbDk_Hzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174966b2-2259-4591-d000-9cc4577432de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, metrics\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKkgf4RAKBOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be27fcab-9c54-4b47-cf74-134afddd246b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (89) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATASET\n",
        "feature_data =pd.read_csv(\"drive/MyDrive/Dataset/DataProcess/SYNandUDPLagDataProcessing.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkGpjg8cAAMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2793b0-a160-4839-8c5e-942e0e43666e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BENIGN' 'Syn' 'UDP' 'UDPLag']\n"
          ]
        }
      ],
      "source": [
        "# ADD LABEL ENCODER\n",
        "label_encoder = LabelEncoder()\n",
        "feature_data[\" Label\"] = label_encoder.fit_transform(feature_data[\" Label\"])\n",
        "datas_labels = label_encoder.classes_\n",
        "print(datas_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpT7d30bAD96"
      },
      "outputs": [],
      "source": [
        "x= feature_data.drop(['Unnamed: 0.1.1','Unnamed: 0','Unnamed: 0.1','SimillarHTTP','Flow ID',' Source IP', ' Destination IP', ' Timestamp'],axis=1)\n",
        "y= feature_data[' Label']\n",
        "\n",
        "x['Flow Bytes/s'] = x['Flow Bytes/s'].round()\n",
        "x['Flow Bytes/s'].fillna(0, inplace = True)\n",
        "x.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "x = x.abs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih0iVzkpAIuv"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "#APPLY CHI SQUARE TO DATASET FEATURE\n",
        "\n",
        "# k = 69 tells four top features to be selected\n",
        "# Score function Chi2 tells the feature to be selected using Chi Square\n",
        "chi_test = SelectKBest(score_func=chi2, k=69)\n",
        "fit = chi_test.fit(x,y)\n",
        "x = chi_test.fit_transform(x, y)\n",
        "x.shape\n",
        "y = y.values.reshape((-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfa78B17AM5D",
        "outputId": "6a8bac80-4f6b-4b6d-fd08-8de2a7cecd3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75000, 69) (75000, 1)\n",
            "(25000, 69) (25000, 1)\n"
          ]
        }
      ],
      "source": [
        "# SPLIT DATASET\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
        "\n",
        "# CHECK THE SHAPE\n",
        "print(x_train.shape , y_train.shape)\n",
        "print(x_test.shape , y_test.shape)\n",
        "\n",
        "# SET TOTAL FOLD\n",
        "total_fold = 10\n",
        "\n",
        "kf = KFold(n_splits = total_fold, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRRmhoyVARS-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyCV5ENpAYPd"
      },
      "outputs": [],
      "source": [
        "def get_stacking1():\n",
        "    level0 = list()\n",
        "    level0.append(('lr', LogisticRegression(penalty='l1',solver=\"liblinear\", random_state=1, max_iter=10000, verbose=1)))\n",
        "    level0.append(('cart', DecisionTreeClassifier(criterion = \"entropy\",random_state=1,max_depth=2)))\n",
        "    level1 = LogisticRegression()\n",
        "    model = StackingClassifier(estimators=level0, final_estimator=level1)\n",
        "    return model\n",
        "\n",
        "def get_stacking2():\n",
        "    level0 = list()\n",
        "    level0.append(('lr', LogisticRegression(penalty='l2',solver=\"liblinear\", random_state=1, max_iter=10000)))\n",
        "    level0.append(('cart', DecisionTreeClassifier(criterion=\"gini\",random_state=1, max_depth=3)))\n",
        "    level1 = LogisticRegression()\n",
        "    model = StackingClassifier(estimators=level0, final_estimator=level1)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e--WwPqoAbdF"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "          RandomForestClassifier(criterion=\"gini\", max_features='sqrt'),\n",
        "          RandomForestClassifier(criterion=\"entropy\", max_features='log2'),\n",
        "          AdaBoostClassifier(algorithm='SAMME', n_estimators=50, learning_rate = 1),\n",
        "          AdaBoostClassifier(algorithm=\"SAMME.R\", n_estimators=100, learning_rate = 0.5),\n",
        "          get_stacking1(),\n",
        "          get_stacking2()\n",
        "          ]\n",
        "classifiers_name = [\n",
        "                    \"RandomForest before Tuning\",\n",
        "                    \"RandomForest after Tuning\",\n",
        "                    \"AdaBoost before Tuning\",\n",
        "                    \"AdaBoost after Tuning\",\n",
        "                    \"Stacking before Tuning\",\n",
        "                    \"Stacking after Tuning\"\n",
        "                    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFV4ex0oAg7r",
        "outputId": "60a3ac82-a8d6-422f-f47d-e6951d0a086b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done fold1\n",
            "Done fold2\n",
            "Done fold3\n",
            "Done fold4\n",
            "Done fold5\n",
            "Done fold6\n",
            "Done fold7\n",
            "Done fold8\n",
            "Done fold9\n",
            "Done fold10\n",
            "Model Accuracy List:  [92.4121212121212, 93.26060606060607, 92.87272727272727, 92.63030303030303, 91.97575757575758, 92.75151515151515, 92.43636363636364, 92.8969696969697, 93.30909090909091, 92.77575757575758]\n",
            "92.73% (+/- 0.38%)\n"
          ]
        }
      ],
      "source": [
        "#RANDOM FOREST BEFORE TUNING\n",
        "\n",
        "fold_number = 0                                        \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index] \n",
        "    y_train_fold = y_train_fold.reshape((-1))\n",
        "    y_test_fold = y_test_fold.reshape((-1))\n",
        "    model = models[0]\n",
        "    model.fit(x_train_fold,y_train_fold)\n",
        "    cvscores.append(model.score(x_test_fold, y_test_fold) * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[0] + \" fold\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "    print(\"Done fold\" + str(fold_number))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[0] + \".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFnDe2bfCfw0",
        "outputId": "58385f2d-51e5-4172-844d-5b214486bc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done fold1\n",
            "Done fold2\n",
            "Done fold3\n",
            "Done fold4\n",
            "Done fold5\n",
            "Done fold6\n",
            "Done fold7\n",
            "Done fold8\n",
            "Done fold9\n",
            "Done fold10\n",
            "Model Accuracy List:  [98.93333333333332, 98.83636363636363, 99.05454545454545, 98.64242424242424, 98.52121212121212, 98.44848484848485, 97.01818181818182, 97.79393939393938, 98.66666666666667, 98.54545454545455]\n",
            "98.45% (+/- 0.58%)\n"
          ]
        }
      ],
      "source": [
        "#RANDOM FOREST AFTER TUNING\n",
        "\n",
        "fold_number = 0                                        \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index] \n",
        "    y_train_fold = y_train_fold.reshape((-1))\n",
        "    y_test_fold = y_test_fold.reshape((-1))\n",
        "    model = models[1]\n",
        "    model.fit(x_train_fold,y_train_fold)\n",
        "    cvscores.append(model.score(x_test_fold, y_test_fold) * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[1] + \" fold\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "    print(\"Done fold\" + str(fold_number))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[1] + \".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCtNA4uvCrUu",
        "outputId": "4db99207-5c96-4d4a-fdde-56818f7e2a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done fold1\n",
            "Done fold2\n",
            "Done fold3\n",
            "Done fold4\n",
            "Done fold5\n",
            "Done fold6\n",
            "Done fold7\n",
            "Done fold8\n",
            "Done fold9\n",
            "Done fold10\n",
            "Model Accuracy List:  [91.32000000000001, 92.14666666666666, 86.29333333333334, 90.17333333333333, 91.64, 91.97333333333333, 84.10666666666667, 91.85333333333332, 91.38666666666667, 92.13333333333334]\n",
            "90.30% (+/- 2.65%)\n"
          ]
        }
      ],
      "source": [
        "#ADABOOST CLASSIFIER BEFORE TUNING\n",
        "\n",
        "fold_number = 0                                        \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index] \n",
        "    y_train_fold = y_train_fold.reshape((-1))\n",
        "    y_test_fold = y_test_fold.reshape((-1))\n",
        "    model = models[2]\n",
        "    model.fit(x_train_fold,y_train_fold)\n",
        "    cvscores.append(model.score(x_test_fold, y_test_fold) * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[2] + \" fold\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "    print(\"Done fold\" + str(fold_number))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[2] + \".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKK7lLYuDCJV",
        "outputId": "e113dbcf-e7bf-4b66-9194-e542ba89e937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done fold1\n",
            "Done fold2\n",
            "Done fold3\n",
            "Done fold4\n",
            "Done fold5\n",
            "Done fold6\n",
            "Done fold7\n",
            "Done fold8\n",
            "Done fold9\n",
            "Done fold10\n",
            "Model Accuracy List:  [93.67999999999999, 95.82666666666667, 95.54666666666667, 96.06666666666666, 92.58666666666666, 95.90666666666667, 95.82666666666667, 90.30666666666667, 96.21333333333332, 93.28]\n",
            "94.52% (+/- 1.88%)\n"
          ]
        }
      ],
      "source": [
        "#ADABOOST CLASSIFIER AFTER TUNING\n",
        "\n",
        "fold_number = 0                                        \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index] \n",
        "    y_train_fold = y_train_fold.reshape((-1))\n",
        "    y_test_fold = y_test_fold.reshape((-1))\n",
        "    model = models[3]\n",
        "    model.fit(x_train_fold,y_train_fold)\n",
        "    cvscores.append(model.score(x_test_fold, y_test_fold) * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[3] + \" fold\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "    print(\"Done fold\" + str(fold_number))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        " \n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[3] + \".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrILL_TmEJK4",
        "outputId": "6515606a-a2ea-464c-db9b-ae9a2fa07484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done fold1\n",
            "Done fold2\n",
            "Done fold3\n",
            "Done fold4\n",
            "Done fold5\n",
            "Done fold6\n",
            "Done fold7\n",
            "Done fold8\n",
            "Done fold9\n",
            "Done fold10\n",
            "Model Accuracy List:  [91.74666666666667, 92.50666666666667, 92.69333333333334, 86.50666666666666, 93.22666666666667, 93.25333333333333, 91.75999999999999, 84.08, 90.57333333333332, 72.14666666666668]\n",
            "88.85% (+/- 6.28%)\n"
          ]
        }
      ],
      "source": [
        "#STACKING BEFORE TUNING \n",
        "\n",
        "fold_number = 0                                        \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index] \n",
        "    y_train_fold = y_train_fold.reshape((-1))\n",
        "    y_test_fold = y_test_fold.reshape((-1))\n",
        "    model = models[4]\n",
        "    model.fit(x_train_fold,y_train_fold)\n",
        "    cvscores.append(model.score(x_test_fold, y_test_fold) * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[4] + \" fold\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "    print(\"Done fold\" + str(fold_number))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[4] + \".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsXyenFbEQck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ae22f7-1175-4110-8113-20947d0888c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done fold1\n",
            "Done fold2\n",
            "Done fold3\n",
            "Done fold4\n",
            "Done fold5\n",
            "Done fold6\n",
            "Done fold7\n",
            "Done fold8\n",
            "Done fold9\n",
            "Done fold10\n",
            "Model Accuracy List:  [97.24000000000001, 96.96000000000001, 96.09333333333333, 97.06666666666666, 97.09333333333333, 97.62666666666667, 97.68, 97.84, 97.24000000000001, 97.62666666666667]\n",
            "97.25% (+/- 0.48%)\n"
          ]
        }
      ],
      "source": [
        "#STACKING AFTER TUNING\n",
        "\n",
        "fold_number = 0                                        \n",
        "cvscores = []\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]                             \n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index] \n",
        "    y_train_fold = y_train_fold.reshape((-1))\n",
        "    y_test_fold = y_test_fold.reshape((-1))\n",
        "    model = models[5]\n",
        "    model.fit(x_train_fold,y_train_fold)\n",
        "    cvscores.append(model.score(x_test_fold, y_test_fold) * 100)\n",
        "    fold_number+=1\n",
        "    fold_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[5] + \" fold\" + str(fold_number) + \".sav\"\n",
        "    pickle.dump(model, open(fold_name, 'wb'))\n",
        "    print(\"Done fold\" + str(fold_number))\n",
        "\n",
        "print(\"Model Accuracy List: \" , cvscores)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[5] + \".sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCc4w9isErkX"
      },
      "outputs": [],
      "source": [
        "#TRAINING DATA SCORES OF RANDOM FOREST\n",
        "\n",
        "file_randomforest_beforetuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[0] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_randomforest_beforetuning_data = [(pickle.load(open(file_randomforest_beforetuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_randomforest_beforetuning_data = [(loaded_randomforest_beforetuning_data[yp].predict(x_train)) for yp in range(total_fold)] \n",
        "y_pred_values_randomforest_beforetuning_data = [y_pred_randomforest_beforetuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_randomforest_beforetuning_data[hehee] = np.reshape(y_pred_values_randomforest_beforetuning_data[hehee],(-1,1))\n",
        "result_randomforest_beforetuning_data = [(classification_report(y_train, y_pred_values_randomforest_beforetuning_data[res], output_dict = True, zero_division=0)) for res in range(total_fold)]\n",
        "\n",
        "file_randomforest_aftertuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[1] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_randomforest_aftertuning_data = [(pickle.load(open(file_randomforest_aftertuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_randomforest_aftertuning_data = [(loaded_randomforest_aftertuning_data[yp].predict(x_train)) for yp in range(total_fold)] \n",
        "y_pred_values_randomforest_aftertuning_data = [y_pred_randomforest_aftertuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_randomforest_aftertuning_data[hehee] = np.reshape(y_pred_values_randomforest_aftertuning_data[hehee],(-1,1))\n",
        "result_randomforest_aftertuning_data = [(classification_report(y_train, y_pred_values_randomforest_aftertuning_data[res], output_dict = True)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2CSRt0bFJCE"
      },
      "outputs": [],
      "source": [
        "#TRAINING DATA SCORES OF ADABOOST\n",
        "\n",
        "file_adaboost_beforetuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[2] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_adaboost_beforetuning_data = [(pickle.load(open(file_adaboost_beforetuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_adaboost_beforetuning_data = [(loaded_adaboost_beforetuning_data[yp].predict(x_train)) for yp in range(total_fold)] \n",
        "y_pred_values_adaboost_beforetuning_data = [y_pred_adaboost_beforetuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_adaboost_beforetuning_data[hehee] = np.reshape(y_pred_values_adaboost_beforetuning_data[hehee],(-1,1))\n",
        "result_adaboost_beforetuning_data = [(classification_report(y_train, y_pred_values_adaboost_beforetuning_data[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "file_adaboost_aftertuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[3] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_adaboost_aftertuning_data = [(pickle.load(open(file_adaboost_aftertuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_adaboost_aftertuning_data = [(loaded_adaboost_aftertuning_data[yp].predict(x_train)) for yp in range(total_fold)] \n",
        "y_pred_values_adaboost_aftertuning_data = [y_pred_adaboost_aftertuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_adaboost_aftertuning_data[hehee] = np.reshape(y_pred_values_adaboost_aftertuning_data[hehee],(-1,1))\n",
        "result_adaboost_aftertuning_data = [(classification_report(y_train, y_pred_values_adaboost_aftertuning_data[res], output_dict = True)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWgEiHW_FmKz"
      },
      "outputs": [],
      "source": [
        "#TRAINING DATA SCORES OF STACKING\n",
        "\n",
        "file_stacking_beforetuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[4] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_stacking_beforetuning_data = [(pickle.load(open(file_stacking_beforetuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_stacking_beforetuning_data = [(loaded_stacking_beforetuning_data[yp].predict(x_train)) for yp in range(total_fold)] \n",
        "y_pred_values_stacking_beforetuning_data = [y_pred_stacking_beforetuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_stacking_beforetuning_data[hehee] = np.reshape(y_pred_values_stacking_beforetuning_data[hehee],(-1,1))\n",
        "result_stacking_beforetuning_data = [(classification_report(y_train, y_pred_values_stacking_beforetuning_data[res], output_dict = True, zero_division=0)) for res in range(total_fold)]\n",
        "\n",
        "file_stacking_aftertuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[5] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_stacking_aftertuning_data = [(pickle.load(open(file_stacking_aftertuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_stacking_aftertuning_data = [(loaded_stacking_aftertuning_data[yp].predict(x_train)) for yp in range(total_fold)] \n",
        "y_pred_values_stacking_aftertuning_data = [y_pred_stacking_aftertuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_stacking_aftertuning_data[hehee] = np.reshape(y_pred_values_stacking_aftertuning_data[hehee],(-1,1))\n",
        "result_stacking_aftertuning_data = [(classification_report(y_train, y_pred_values_stacking_aftertuning_data[res], output_dict = True, zero_division=0)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H64u5UGcxHJF"
      },
      "outputs": [],
      "source": [
        "training_precision_list_before = {}\n",
        "training_precision_list_after = {}\n",
        "training_recall_list_before = {}\n",
        "training_recall_list_after = {}\n",
        "training_accuracy_list_before = {}\n",
        "training_accuracy_list_after = {}\n",
        "training_f1_list_before = {}\n",
        "training_f1_list_after = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnU9sEsp_t38"
      },
      "outputs": [],
      "source": [
        "for scr in range(total_fold):\n",
        "  training_precision_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['macro avg']['precision'] , result_adaboost_beforetuning_data[scr]['macro avg']['precision'], result_stacking_beforetuning_data[scr]['macro avg']['precision']]\n",
        "  training_precision_list_after[(scr+1)] = [result_randomforest_aftertuning_data[scr]['macro avg']['precision'] , result_adaboost_aftertuning_data[scr]['macro avg']['precision'], result_stacking_aftertuning_data[scr]['macro avg']['precision']]\n",
        "  training_recall_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['macro avg']['recall'] , result_adaboost_beforetuning_data[scr]['macro avg']['recall'], result_stacking_beforetuning_data[scr]['macro avg']['recall']]\n",
        "  training_recall_list_after[(scr+1)] = [result_randomforest_aftertuning_data[scr]['macro avg']['recall'] , result_adaboost_aftertuning_data[scr]['macro avg']['recall'], result_stacking_aftertuning_data[scr]['macro avg']['recall']]\n",
        "  training_accuracy_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['accuracy'] , result_adaboost_beforetuning_data[scr]['accuracy'], result_stacking_beforetuning_data[scr]['accuracy']]\n",
        "  training_accuracy_list_after[(scr+1)] = [result_randomforest_aftertuning_data[scr]['accuracy'] , result_adaboost_aftertuning_data[scr]['accuracy'], result_stacking_aftertuning_data[scr]['accuracy']]\n",
        "  training_f1_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['macro avg']['f1-score'] , result_adaboost_beforetuning_data[scr]['macro avg']['f1-score'], result_stacking_beforetuning_data[scr]['macro avg']['f1-score']]\n",
        "  training_f1_list_after [(scr+1)] = [result_randomforest_aftertuning_data[scr]['macro avg']['f1-score'] , result_adaboost_aftertuning_data[scr]['macro avg']['f1-score'], result_stacking_aftertuning_data[scr]['macro avg']['f1-score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQAWRHbQB168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2591dd8d-f72f-4621-af72-cff7d48333d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Precision K-Fold Training Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.710           0.668      0.654     \n",
            "2        0.710           0.677      0.647     \n",
            "3        0.711           0.707      0.647     \n",
            "4        0.715           0.578      0.718     \n",
            "5        0.666           0.652      0.679     \n",
            "6        0.710           0.647      0.667     \n",
            "7        0.686           0.482      0.637     \n",
            "8        0.710           0.645      0.488     \n",
            "9        0.711           0.672      0.656     \n",
            "10       0.710           0.667      0.469     \n",
            "\n",
            "\n",
            "  Precision K-Fold Training Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.849           0.607      0.715     \n",
            "2        0.976           0.735      0.714     \n",
            "3        0.873           0.793      0.709     \n",
            "4        0.981           0.695      0.715     \n",
            "5        0.973           0.759      0.711     \n",
            "6        0.870           0.808      0.716     \n",
            "7        0.871           0.803      0.716     \n",
            "8        0.843           0.722      0.717     \n",
            "9        0.870           0.810      0.716     \n",
            "10       0.868           0.745      0.716     \n",
            "\n",
            "\n",
            "  Recall K-Fold Training Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.748           0.562      0.564     \n",
            "2        0.749           0.579      0.572     \n",
            "3        0.749           0.663      0.575     \n",
            "4        0.748           0.583      0.644     \n",
            "5        0.746           0.560      0.580     \n",
            "6        0.743           0.582      0.576     \n",
            "7        0.747           0.472      0.568     \n",
            "8        0.748           0.586      0.461     \n",
            "9        0.749           0.550      0.527     \n",
            "10       0.749           0.581      0.551     \n",
            "\n",
            "\n",
            "  Recall K-Fold Training Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.954           0.674      0.706     \n",
            "2        0.955           0.627      0.691     \n",
            "3        0.965           0.674      0.637     \n",
            "4        0.940           0.658      0.700     \n",
            "5        0.974           0.781      0.665     \n",
            "6        0.930           0.633      0.719     \n",
            "7        0.964           0.654      0.727     \n",
            "8        0.902           0.627      0.724     \n",
            "9        0.944           0.675      0.716     \n",
            "10       0.944           0.722      0.721     \n",
            "\n",
            "\n",
            "  Accuracy K-Fold Training Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.980           0.917      0.922     \n",
            "2        0.980           0.920      0.923     \n",
            "3        0.980           0.861      0.928     \n",
            "4        0.980           0.906      0.862     \n",
            "5        0.971           0.918      0.929     \n",
            "6        0.979           0.916      0.931     \n",
            "7        0.975           0.835      0.924     \n",
            "8        0.980           0.918      0.833     \n",
            "9        0.980           0.916      0.906     \n",
            "10       0.980           0.920      0.727     \n",
            "\n",
            "\n",
            "  Accuracy K-Fold  Training Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.942           0.936      0.974     \n",
            "2        0.995           0.957      0.971     \n",
            "3        0.960           0.961      0.963     \n",
            "4        0.994           0.962      0.973     \n",
            "5        0.995           0.928      0.967     \n",
            "6        0.959           0.958      0.976     \n",
            "7        0.959           0.960      0.977     \n",
            "8        0.938           0.902      0.976     \n",
            "9        0.959           0.961      0.975     \n",
            "10       0.958           0.935      0.976     \n",
            "\n",
            "\n",
            "  F1-Score K-Fold Training Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.728           0.591      0.586     \n",
            "2        0.729           0.611      0.591     \n",
            "3        0.729           0.578      0.598     \n",
            "4        0.731           0.579      0.559     \n",
            "5        0.701           0.589      0.610     \n",
            "6        0.725           0.606      0.603     \n",
            "7        0.714           0.425      0.591     \n",
            "8        0.728           0.608      0.410     \n",
            "9        0.729           0.583      0.566     \n",
            "10       0.729           0.610      0.458     \n",
            "\n",
            "\n",
            "  F1-Score K-Fold  Training Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.868           0.620      0.709     \n",
            "2        0.964           0.650      0.699     \n",
            "3        0.896           0.681      0.658     \n",
            "4        0.956           0.669      0.704     \n",
            "5        0.972           0.722      0.681     \n",
            "6        0.875           0.664      0.716     \n",
            "7        0.894           0.679      0.721     \n",
            "8        0.832           0.631      0.719     \n",
            "9        0.883           0.709      0.714     \n",
            "10       0.882           0.707      0.718     \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"{:<1} {:<0}\".format(\"\",\"Precision K-Fold Training Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_precision_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Precision K-Fold Training Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_precision_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Recall K-Fold Training Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_recall_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Recall K-Fold Training Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_recall_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Accuracy K-Fold Training Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_accuracy_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Accuracy K-Fold  Training Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_accuracy_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"F1-Score K-Fold Training Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_f1_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"F1-Score K-Fold  Training Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in training_f1_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ECgcuuNVsAm"
      },
      "outputs": [],
      "source": [
        "#TEST DATA SCORES OF RANDOM FOREST\n",
        "\n",
        "file_randomforest_beforetuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[0] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_randomforest_beforetuning_data = [(pickle.load(open(file_randomforest_beforetuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_randomforest_beforetuning_data = [(loaded_randomforest_beforetuning_data[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_randomforest_beforetuning_data = [y_pred_randomforest_beforetuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_randomforest_beforetuning_data[hehee] = np.reshape(y_pred_values_randomforest_beforetuning_data[hehee],(-1,1))\n",
        "result_randomforest_beforetuning_data = [(classification_report(y_test, y_pred_values_randomforest_beforetuning_data[res], output_dict = True, zero_division=0)) for res in range(total_fold)]\n",
        "\n",
        "file_randomforest_aftertuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[1] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_randomforest_aftertuning_data = [(pickle.load(open(file_randomforest_aftertuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_randomforest_aftertuning_data = [(loaded_randomforest_aftertuning_data[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_randomforest_aftertuning_data = [y_pred_randomforest_aftertuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_randomforest_aftertuning_data[hehee] = np.reshape(y_pred_values_randomforest_aftertuning_data[hehee],(-1,1))\n",
        "result_randomforest_aftertuning_data = [(classification_report(y_test, y_pred_values_randomforest_aftertuning_data[res], output_dict = True)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ovRuTWAV1Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e883b9-7c33-40af-a882-b3450eba1764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#TEST DATA SCORES OF ADABOOST\n",
        "\n",
        "file_adaboost_beforetuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[2] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_adaboost_beforetuning_data = [(pickle.load(open(file_adaboost_beforetuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_adaboost_beforetuning_data = [(loaded_adaboost_beforetuning_data[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_adaboost_beforetuning_data = [y_pred_adaboost_beforetuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_adaboost_beforetuning_data[hehee] = np.reshape(y_pred_values_adaboost_beforetuning_data[hehee],(-1,1))\n",
        "result_adaboost_beforetuning_data = [(classification_report(y_test, y_pred_values_adaboost_beforetuning_data[res], output_dict = True)) for res in range(total_fold)]\n",
        "\n",
        "file_adaboost_aftertuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[3] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_adaboost_aftertuning_data = [(pickle.load(open(file_adaboost_aftertuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_adaboost_aftertuning_data = [(loaded_adaboost_aftertuning_data[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_adaboost_aftertuning_data = [y_pred_adaboost_aftertuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_adaboost_aftertuning_data[hehee] = np.reshape(y_pred_values_adaboost_aftertuning_data[hehee],(-1,1))\n",
        "result_adaboost_aftertuning_data = [(classification_report(y_test, y_pred_values_adaboost_aftertuning_data[res], output_dict = True)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvtwoSgmWAk0"
      },
      "outputs": [],
      "source": [
        "#TEST DATA SCORES OF STACKING\n",
        "\n",
        "file_stacking_beforetuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[4] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_stacking_beforetuning_data = [(pickle.load(open(file_stacking_beforetuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_stacking_beforetuning_data = [(loaded_stacking_beforetuning_data[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_stacking_beforetuning_data = [y_pred_stacking_beforetuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_stacking_beforetuning_data[hehee] = np.reshape(y_pred_values_stacking_beforetuning_data[hehee],(-1,1))\n",
        "result_stacking_beforetuning_data = [(classification_report(y_test, y_pred_values_stacking_beforetuning_data[res], output_dict = True, zero_division=0)) for res in range(total_fold)]\n",
        "\n",
        "file_stacking_aftertuning_data = [(\"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[5] + \" fold\" + str(fn+1) + \".sav\") for fn in range(total_fold)]\n",
        "loaded_stacking_aftertuning_data = [(pickle.load(open(file_stacking_aftertuning_data[lm], \"rb\"))) for lm in range(total_fold)]\n",
        "y_pred_stacking_aftertuning_data = [(loaded_stacking_aftertuning_data[yp].predict(x_test)) for yp in range(total_fold)] \n",
        "y_pred_values_stacking_aftertuning_data = [y_pred_stacking_aftertuning_data[ypv] for ypv in range(total_fold)]\n",
        "for hehee in range(total_fold):\n",
        "  y_pred_values_stacking_aftertuning_data[hehee] = np.reshape(y_pred_values_stacking_aftertuning_data[hehee],(-1,1))\n",
        "result_stacking_aftertuning_data = [(classification_report(y_test, y_pred_values_stacking_aftertuning_data[res], output_dict = True, zero_division=0)) for res in range(total_fold)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_precision_list_before = {}\n",
        "test_precision_list_after = {}\n",
        "test_recall_list_before = {}\n",
        "test_recall_list_after = {}\n",
        "test_accuracy_list_before = {}\n",
        "test_accuracy_list_after = {}\n",
        "test_f1_list_before = {}\n",
        "test_f1_list_after = {}"
      ],
      "metadata": {
        "id": "PTrGQauQFgfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxA0RWDMXp2p"
      },
      "outputs": [],
      "source": [
        "for scr in range(total_fold):\n",
        "  test_precision_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['macro avg']['precision'] , result_adaboost_beforetuning_data[scr]['macro avg']['precision'], result_stacking_beforetuning_data[scr]['macro avg']['precision']]\n",
        "  test_precision_list_after[(scr+1)] = [result_randomforest_aftertuning_data[scr]['macro avg']['precision'] , result_adaboost_aftertuning_data[scr]['macro avg']['precision'], result_stacking_aftertuning_data[scr]['macro avg']['precision']]\n",
        "  test_recall_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['macro avg']['recall'] , result_adaboost_beforetuning_data[scr]['macro avg']['recall'], result_stacking_beforetuning_data[scr]['macro avg']['recall']]\n",
        "  test_recall_list_after[(scr+1)] = [result_randomforest_aftertuning_data[scr]['macro avg']['recall'] , result_adaboost_aftertuning_data[scr]['macro avg']['recall'], result_stacking_aftertuning_data[scr]['macro avg']['recall']]\n",
        "  test_accuracy_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['accuracy'] , result_adaboost_beforetuning_data[scr]['accuracy'], result_stacking_beforetuning_data[scr]['accuracy']]\n",
        "  test_accuracy_list_after[(scr+1)] = [result_randomforest_aftertuning_data[scr]['accuracy'] , result_adaboost_aftertuning_data[scr]['accuracy'], result_stacking_aftertuning_data[scr]['accuracy']]\n",
        "  test_f1_list_before[(scr+1)] = [result_randomforest_beforetuning_data[scr]['macro avg']['f1-score'] , result_adaboost_beforetuning_data[scr]['macro avg']['f1-score'], result_stacking_beforetuning_data[scr]['macro avg']['precision']]\n",
        "  test_f1_list_after[(scr+1)] = [result_randomforest_aftertuning_data[scr]['macro avg']['f1-score'] , result_adaboost_aftertuning_data[scr]['macro avg']['f1-score'], result_stacking_aftertuning_data[scr]['macro avg']['precision']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py1FrArpXu1B",
        "outputId": "c74bbde0-a99e-430c-f5f7-33ae3fe6ae07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Precision K-Fold Test Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.709           0.661      0.656     \n",
            "2        0.710           0.677      0.638     \n",
            "3        0.709           0.701      0.643     \n",
            "4        0.714           0.577      0.712     \n",
            "5        0.666           0.646      0.677     \n",
            "6        0.709           0.646      0.664     \n",
            "7        0.686           0.475      0.627     \n",
            "8        0.709           0.640      0.483     \n",
            "9        0.710           0.668      0.654     \n",
            "10       0.709           0.667      0.468     \n",
            "\n",
            "\n",
            "  Precision K-Fold Test Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.847           0.597      0.715     \n",
            "2        0.973           0.749      0.714     \n",
            "3        0.872           0.785      0.708     \n",
            "4        0.980           0.690      0.715     \n",
            "5        0.971           0.754      0.710     \n",
            "6        0.869           0.796      0.716     \n",
            "7        0.869           0.784      0.715     \n",
            "8        0.841           0.718      0.717     \n",
            "9        0.869           0.807      0.715     \n",
            "10       0.868           0.734      0.716     \n",
            "\n",
            "\n",
            "  Recall K-Fold Test Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.747           0.561      0.562     \n",
            "2        0.749           0.579      0.572     \n",
            "3        0.748           0.662      0.576     \n",
            "4        0.748           0.585      0.640     \n",
            "5        0.745           0.559      0.581     \n",
            "6        0.742           0.584      0.575     \n",
            "7        0.747           0.470      0.566     \n",
            "8        0.748           0.585      0.458     \n",
            "9        0.749           0.549      0.526     \n",
            "10       0.748           0.582      0.553     \n",
            "\n",
            "\n",
            "  Recall K-Fold Test Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.954           0.674      0.708     \n",
            "2        0.958           0.634      0.695     \n",
            "3        0.963           0.674      0.632     \n",
            "4        0.939           0.658      0.701     \n",
            "5        0.973           0.776      0.661     \n",
            "6        0.930           0.636      0.722     \n",
            "7        0.962           0.657      0.730     \n",
            "8        0.900           0.629      0.726     \n",
            "9        0.946           0.679      0.717     \n",
            "10       0.947           0.717      0.724     \n",
            "\n",
            "\n",
            "  Accuracy K-Fold Test Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.980           0.916      0.922     \n",
            "2        0.980           0.919      0.922     \n",
            "3        0.980           0.860      0.928     \n",
            "4        0.980           0.906      0.861     \n",
            "5        0.971           0.917      0.929     \n",
            "6        0.979           0.915      0.931     \n",
            "7        0.975           0.832      0.922     \n",
            "8        0.980           0.917      0.830     \n",
            "9        0.980           0.915      0.906     \n",
            "10       0.980           0.920      0.726     \n",
            "\n",
            "\n",
            "  Accuracy K-Fold  Test Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.942           0.934      0.974     \n",
            "2        0.995           0.958      0.972     \n",
            "3        0.961           0.960      0.963     \n",
            "4        0.994           0.961      0.973     \n",
            "5        0.995           0.926      0.967     \n",
            "6        0.959           0.958      0.976     \n",
            "7        0.959           0.960      0.977     \n",
            "8        0.938           0.901      0.977     \n",
            "9        0.959           0.961      0.975     \n",
            "10       0.958           0.933      0.976     \n",
            "\n",
            "\n",
            "  F-1Score K-Fold Test Data Before Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.727           0.588      0.656     \n",
            "2        0.728           0.610      0.638     \n",
            "3        0.728           0.577      0.643     \n",
            "4        0.730           0.579      0.712     \n",
            "5        0.702           0.586      0.677     \n",
            "6        0.725           0.606      0.664     \n",
            "7        0.714           0.419      0.627     \n",
            "8        0.728           0.605      0.483     \n",
            "9        0.728           0.581      0.654     \n",
            "10       0.728           0.609      0.468     \n",
            "\n",
            "\n",
            "  F-1Score K-Fold  Test Data After Tuning\n",
            "Fold     Random Forest   Adaboost   Stacking  \n",
            "1        0.866           0.617      0.715     \n",
            "2        0.964           0.656      0.714     \n",
            "3        0.895           0.676      0.708     \n",
            "4        0.956           0.667      0.715     \n",
            "5        0.971           0.719      0.710     \n",
            "6        0.875           0.662      0.716     \n",
            "7        0.892           0.677      0.715     \n",
            "8        0.829           0.631      0.717     \n",
            "9        0.883           0.710      0.715     \n",
            "10       0.883           0.703      0.716     \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"{:<1} {:<0}\".format(\"\",\"Precision K-Fold Test Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_precision_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Precision K-Fold Test Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_precision_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Recall K-Fold Test Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_recall_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Recall K-Fold Test Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_recall_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Accuracy K-Fold Test Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_accuracy_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"Accuracy K-Fold  Test Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_accuracy_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"F-1Score K-Fold Test Data Before Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_f1_list_before.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"{:<1} {:<0}\".format(\"\",\"F-1Score K-Fold  Test Data After Tuning\"))\n",
        "print (\"{:<8} {:<15} {:<10} {:<10}\".format('Fold','Random Forest','Adaboost','Stacking'))\n",
        "for k, v in test_f1_list_after.items():\n",
        "    random_forest_fold_data, adaboost_fold_data, stacking_fold_data = v\n",
        "    print (\"{:<8} {:<15} {:<10} {:<10}\".format(k, format(random_forest_fold_data,\".3f\"), format(adaboost_fold_data,\".3f\"), format(stacking_fold_data,\".3f\") ))\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = label_encoder.inverse_transform(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxcD3B30Zp6R",
        "outputId": "59c4f844-baeb-43f2-d118-2a77b59a830c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaboost Folds Before Tuning Confusion Matrix\n",
        "prev_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  fold_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[2] + \" fold\" + str(fold_of+1) + \".sav\"\n",
        "  fold_model = pickle.load(open(fold_model_name, \"rb\"))\n",
        "  y_pred_fold = fold_model.predict(x_test)\n",
        "  y_pred_fold = np.reshape(y_pred_fold, (-1,1))\n",
        "  print(\"\")\n",
        "  print(\"Adaboost Before Tuning Confusion Matrix Fold \" + str(fold_of+1))\n",
        "  y_pred_fold = label_encoder.inverse_transform(y_pred_fold)\n",
        "  fold_cf = confusion_matrix(y_test, y_pred_fold, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',fold_cf[0][0],fold_cf[0][1],fold_cf[0][2],fold_cf[0][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',fold_cf[1][0],fold_cf[1][1],fold_cf[1][2],fold_cf[1][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',fold_cf[2][0],fold_cf[2][1],fold_cf[1][2],fold_cf[2][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',fold_cf[3][0],fold_cf[3][1],fold_cf[3][2],fold_cf[3][3]))\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred_fold, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo7DQYc0NDyH",
        "outputId": "4ecc398a-c447-4d15-9f9e-3fa124d3f563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 1\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     404        169        308        45        \n",
            "Syn        12         19330      326        62        \n",
            "UDP        16         687        326        0         \n",
            "UDPLag     20         9          439        5         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.89      0.44      0.59       926\n",
            "         Syn       0.96      0.98      0.97     19730\n",
            "         UDP       0.75      0.82      0.78      3871\n",
            "      UDPLag       0.04      0.01      0.02       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.66      0.56      0.59     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 2\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     477        171        231        47        \n",
            "Syn        9          19379      270        72        \n",
            "UDP        7          755        270        1         \n",
            "UDPLag     19         9          438        7         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.93      0.52      0.66       926\n",
            "         Syn       0.95      0.98      0.97     19730\n",
            "         UDP       0.77      0.80      0.79      3871\n",
            "      UDPLag       0.06      0.01      0.02       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.68      0.58      0.61     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 3\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     409        253        209        55        \n",
            "Syn        3          19439      198        90        \n",
            "UDP        8          802        198        1832      \n",
            "UDPLag     19         15         12         427       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.93      0.44      0.60       926\n",
            "         Syn       0.95      0.99      0.97     19730\n",
            "         UDP       0.75      0.32      0.45      3871\n",
            "      UDPLag       0.18      0.90      0.30       473\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.70      0.66      0.58     25000\n",
            "weighted avg       0.90      0.86      0.86     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 4\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     523        143        219        41        \n",
            "Syn        338        19025      293        74        \n",
            "UDP        64         705        293        0         \n",
            "UDPLag     22         9          438        4         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.55      0.56      0.56       926\n",
            "         Syn       0.96      0.96      0.96     19730\n",
            "         UDP       0.77      0.80      0.78      3871\n",
            "      UDPLag       0.03      0.01      0.01       473\n",
            "\n",
            "    accuracy                           0.91     25000\n",
            "   macro avg       0.58      0.58      0.58     25000\n",
            "weighted avg       0.89      0.91      0.90     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 5\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     413        241        233        39        \n",
            "Syn        13         19396      263        58        \n",
            "UDP        45         715        263        0         \n",
            "UDPLag     20         13         438        2         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.84      0.45      0.58       926\n",
            "         Syn       0.95      0.98      0.97     19730\n",
            "         UDP       0.77      0.80      0.79      3871\n",
            "      UDPLag       0.02      0.00      0.01       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.65      0.56      0.59     25000\n",
            "weighted avg       0.90      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 6\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     515        150        217        44        \n",
            "Syn        81         19290      292        67        \n",
            "UDP        9          796        292        0         \n",
            "UDPLag     20         10         438        5         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.82      0.56      0.66       926\n",
            "         Syn       0.95      0.98      0.97     19730\n",
            "         UDP       0.76      0.79      0.78      3871\n",
            "      UDPLag       0.04      0.01      0.02       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.65      0.58      0.61     25000\n",
            "weighted avg       0.90      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 7\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     547        145        191        43        \n",
            "Syn        414        19027      191        98        \n",
            "UDP        1899       740        191        0         \n",
            "UDPLag     449        10         11         3         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.17      0.59      0.26       926\n",
            "         Syn       0.96      0.96      0.96     19730\n",
            "         UDP       0.76      0.32      0.45      3871\n",
            "      UDPLag       0.02      0.01      0.01       473\n",
            "\n",
            "    accuracy                           0.83     25000\n",
            "   macro avg       0.47      0.47      0.42     25000\n",
            "weighted avg       0.88      0.83      0.84     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 8\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     516        155        207        48        \n",
            "Syn        45         19328      279        78        \n",
            "UDP        67         729        279        0         \n",
            "UDPLag     21         10         437        5         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.80      0.56      0.66       926\n",
            "         Syn       0.96      0.98      0.97     19730\n",
            "         UDP       0.77      0.79      0.78      3871\n",
            "      UDPLag       0.04      0.01      0.02       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.64      0.59      0.61     25000\n",
            "weighted avg       0.90      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 9\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     378        274        236        38        \n",
            "Syn        2          19412      259        57        \n",
            "UDP        7          775        259        0         \n",
            "UDPLag     18         15         438        2         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.93      0.41      0.57       926\n",
            "         Syn       0.95      0.98      0.97     19730\n",
            "         UDP       0.77      0.80      0.78      3871\n",
            "      UDPLag       0.02      0.00      0.01       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.67      0.55      0.58     25000\n",
            "weighted avg       0.90      0.92      0.90     25000\n",
            "\n",
            "\n",
            "Adaboost Before Tuning Confusion Matrix Fold 10\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     482        160        242        42        \n",
            "Syn        6          19358      285        81        \n",
            "UDP        29         686        285        0         \n",
            "UDPLag     21         8          438        6         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.90      0.52      0.66       926\n",
            "         Syn       0.96      0.98      0.97     19730\n",
            "         UDP       0.77      0.82      0.79      3871\n",
            "      UDPLag       0.05      0.01      0.02       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.67      0.58      0.61     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaboost Folds After Tuning Confusion Matrix\n",
        "prev_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  fold_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[3] + \" fold\" + str(fold_of+1) + \".sav\"\n",
        "  fold_model = pickle.load(open(fold_model_name, \"rb\"))\n",
        "  y_pred_fold = fold_model.predict(x_test)\n",
        "  y_pred_fold = np.reshape(y_pred_fold, (-1,1))\n",
        "  print(\"\")\n",
        "  print(\"Adaboost After Tuning Confusion Matrix Fold \" + str(fold_of+1))\n",
        "  y_pred_fold = label_encoder.inverse_transform(y_pred_fold)\n",
        "  fold_cf = confusion_matrix(y_test, y_pred_fold, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',fold_cf[0][0],fold_cf[0][1],fold_cf[0][2],fold_cf[0][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',fold_cf[1][0],fold_cf[1][1],fold_cf[1][2],fold_cf[1][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',fold_cf[2][0],fold_cf[2][1],fold_cf[1][2],fold_cf[2][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',fold_cf[3][0],fold_cf[3][1],fold_cf[3][2],fold_cf[3][3]))\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred_fold, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0sU9HRPNILM",
        "outputId": "547e6ba3-edbf-449f-c34f-0b5c6c008f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 1\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     690        216        9          11        \n",
            "Syn        780        18810      140        0         \n",
            "UDP        17         3          140        1         \n",
            "UDPLag     34         9          429        1         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.45      0.75      0.56       926\n",
            "         Syn       0.99      0.95      0.97     19730\n",
            "         UDP       0.87      0.99      0.93      3871\n",
            "      UDPLag       0.08      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.93     25000\n",
            "   macro avg       0.60      0.67      0.62     25000\n",
            "weighted avg       0.93      0.93      0.93     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 2\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     493        372        36         25        \n",
            "Syn        3          19587      136        4         \n",
            "UDP        10         5          136        2         \n",
            "UDPLag     15         20         430        8         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      0.53      0.68       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.86      1.00      0.93      3871\n",
            "      UDPLag       0.21      0.02      0.03       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.75      0.63      0.66     25000\n",
            "weighted avg       0.95      0.96      0.95     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 3\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     655        229        34         8         \n",
            "Syn        49         19541      138        2         \n",
            "UDP        70         3          138        0         \n",
            "UDPLag     29         12         423        9         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.82      0.71      0.76       926\n",
            "         Syn       0.99      0.99      0.99     19730\n",
            "         UDP       0.86      0.98      0.92      3871\n",
            "      UDPLag       0.47      0.02      0.04       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.79      0.67      0.68     25000\n",
            "weighted avg       0.95      0.96      0.95     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 4\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     596        303        26         1         \n",
            "Syn        12         19579      139        0         \n",
            "UDP        15         5          139        0         \n",
            "UDPLag     32         13         428        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.91      0.64      0.75       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.87      0.99      0.93      3871\n",
            "      UDPLag       0.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.69      0.66      0.67     25000\n",
            "weighted avg       0.94      0.96      0.95     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 5\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     628        247        25         26        \n",
            "Syn        30         19551      126        23        \n",
            "UDP        17         2          126        1231      \n",
            "UDPLag     32         12         71         358       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.89      0.68      0.77       926\n",
            "         Syn       0.99      0.99      0.99     19730\n",
            "         UDP       0.92      0.68      0.78      3871\n",
            "      UDPLag       0.22      0.76      0.34       473\n",
            "\n",
            "    accuracy                           0.93     25000\n",
            "   macro avg       0.75      0.78      0.72     25000\n",
            "weighted avg       0.96      0.93      0.94     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 6\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     487        364        61         14        \n",
            "Syn        0          19590      137        3         \n",
            "UDP        4          5          137        8         \n",
            "UDPLag     3          16         440        14        \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.99      0.53      0.69       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.86      1.00      0.92      3871\n",
            "      UDPLag       0.36      0.03      0.05       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.80      0.64      0.66     25000\n",
            "weighted avg       0.95      0.96      0.95     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 7\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     569        343        11         3         \n",
            "Syn        10         19584      131        5         \n",
            "UDP        16         4          131        17        \n",
            "UDPLag     32         13         413        15        \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.91      0.61      0.73       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.87      0.99      0.93      3871\n",
            "      UDPLag       0.38      0.03      0.06       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.78      0.66      0.68     25000\n",
            "weighted avg       0.95      0.96      0.95     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 8\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     491        403        22         10        \n",
            "Syn        6          19586      125        13        \n",
            "UDP        7          20         125        1592      \n",
            "UDPLag     23         19         236        195       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.93      0.53      0.68       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.85      0.58      0.69      3871\n",
            "      UDPLag       0.11      0.41      0.17       473\n",
            "\n",
            "    accuracy                           0.90     25000\n",
            "   macro avg       0.72      0.63      0.63     25000\n",
            "weighted avg       0.94      0.90      0.91     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 9\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     587        300        37         2         \n",
            "Syn        14         19573      135        8         \n",
            "UDP        6          5          135        56        \n",
            "UDPLag     17         16         390        50        \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.94      0.63      0.76       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.87      0.98      0.92      3871\n",
            "      UDPLag       0.43      0.11      0.17       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.81      0.68      0.71     25000\n",
            "weighted avg       0.95      0.96      0.95     25000\n",
            "\n",
            "\n",
            "Adaboost After Tuning Confusion Matrix Fold 10\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     523        357        26         20        \n",
            "Syn        60         19533      125        12        \n",
            "UDP        17         3          125        837       \n",
            "UDPLag     32         12         176        253       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.83      0.56      0.67       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.90      0.78      0.84      3871\n",
            "      UDPLag       0.23      0.53      0.32       473\n",
            "\n",
            "    accuracy                           0.93     25000\n",
            "   macro avg       0.73      0.72      0.70     25000\n",
            "weighted avg       0.95      0.93      0.94     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacking Folds Before Tuning Confusion Matrix\n",
        "prev_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  fold_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[4] + \" fold\" + str(fold_of+1) + \".sav\"\n",
        "  fold_model = pickle.load(open(fold_model_name, \"rb\"))\n",
        "  y_pred_fold = fold_model.predict(x_test)\n",
        "  y_pred_fold = np.reshape(y_pred_fold, (-1,1))\n",
        "  print(\"\")\n",
        "  print(\"Stacking Before Tuning Confusion Matrix Fold \" + str(fold_of+1))\n",
        "  y_pred_fold = label_encoder.inverse_transform(y_pred_fold)\n",
        "  fold_cf = confusion_matrix(y_test, y_pred_fold, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',fold_cf[0][0],fold_cf[0][1],fold_cf[0][2],fold_cf[0][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',fold_cf[1][0],fold_cf[1][1],fold_cf[1][2],fold_cf[1][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',fold_cf[2][0],fold_cf[2][1],fold_cf[1][2],fold_cf[2][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',fold_cf[3][0],fold_cf[3][1],fold_cf[3][2],fold_cf[3][3]))\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred_fold, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqvswRKFNZze",
        "outputId": "1f65c192-6f5a-40fb-d32c-3c60092b8125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 1\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     373        236        315        2         \n",
            "Syn        20         19336      312        62        \n",
            "UDP        7          529        312        0         \n",
            "UDPLag     20         12         440        1         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.89      0.40      0.55       926\n",
            "         Syn       0.96      0.98      0.97     19730\n",
            "         UDP       0.76      0.86      0.81      3871\n",
            "      UDPLag       0.02      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.66      0.56      0.58     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 2\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     428        268        221        9         \n",
            "Syn        196        19402      117        15        \n",
            "UDP        10         636        117        1         \n",
            "UDPLag     21         11         437        4         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.65      0.46      0.54       926\n",
            "         Syn       0.95      0.98      0.97     19730\n",
            "         UDP       0.81      0.83      0.82      3871\n",
            "      UDPLag       0.14      0.01      0.02       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.64      0.57      0.59     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 3\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     425        206        253        42        \n",
            "Syn        86         19467      112        65        \n",
            "UDP        10         559        112        0         \n",
            "UDPLag     20         14         437        2         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.79      0.46      0.58       926\n",
            "         Syn       0.96      0.99      0.97     19730\n",
            "         UDP       0.80      0.85      0.83      3871\n",
            "      UDPLag       0.02      0.00      0.01       473\n",
            "\n",
            "    accuracy                           0.93     25000\n",
            "   macro avg       0.64      0.58      0.60     25000\n",
            "weighted avg       0.91      0.93      0.92     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 4\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     321        374        172        59        \n",
            "Syn        4          19548      100        78        \n",
            "UDP        6          809        100        1840      \n",
            "UDPLag     19         15         10         429       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.92      0.35      0.50       926\n",
            "         Syn       0.94      0.99      0.97     19730\n",
            "         UDP       0.81      0.31      0.45      3871\n",
            "      UDPLag       0.18      0.91      0.30       473\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.71      0.64      0.56     25000\n",
            "weighted avg       0.91      0.86      0.86     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 5\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     452        198        239        37        \n",
            "Syn        4          19515      144        67        \n",
            "UDP        9          603        144        0         \n",
            "UDPLag     20         13         438        2         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.93      0.49      0.64       926\n",
            "         Syn       0.96      0.99      0.97     19730\n",
            "         UDP       0.80      0.84      0.82      3871\n",
            "      UDPLag       0.02      0.00      0.01       473\n",
            "\n",
            "    accuracy                           0.93     25000\n",
            "   macro avg       0.68      0.58      0.61     25000\n",
            "weighted avg       0.92      0.93      0.92     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 6\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     405        274        206        41        \n",
            "Syn        44         19502      117        67        \n",
            "UDP        10         508        117        0         \n",
            "UDPLag     20         12         437        4         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.85      0.44      0.58       926\n",
            "         Syn       0.96      0.99      0.97     19730\n",
            "         UDP       0.82      0.87      0.84      3871\n",
            "      UDPLag       0.04      0.01      0.01       473\n",
            "\n",
            "    accuracy                           0.93     25000\n",
            "   macro avg       0.66      0.58      0.60     25000\n",
            "weighted avg       0.92      0.93      0.92     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 7\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     407        189        227        103       \n",
            "Syn        78         19418      169        65        \n",
            "UDP        48         589        169        1         \n",
            "UDPLag     20         12         438        3         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.74      0.44      0.55       926\n",
            "         Syn       0.96      0.98      0.97     19730\n",
            "         UDP       0.79      0.84      0.81      3871\n",
            "      UDPLag       0.02      0.01      0.01       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.63      0.57      0.59     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 8\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     552        259        115        0         \n",
            "Syn        395        19175      96         64        \n",
            "UDP        1851       993        96         0         \n",
            "UDPLag     450        13         10         0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.17      0.60      0.26       926\n",
            "         Syn       0.94      0.97      0.95     19730\n",
            "         UDP       0.82      0.27      0.40      3871\n",
            "      UDPLag       0.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.83     25000\n",
            "   macro avg       0.48      0.46      0.41     25000\n",
            "weighted avg       0.87      0.83      0.83     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 9\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     379        266        274        7         \n",
            "Syn        6          19537      119        68        \n",
            "UDP        9          1129       119        0         \n",
            "UDPLag     20         14         439        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.92      0.41      0.57       926\n",
            "         Syn       0.93      0.99      0.96     19730\n",
            "         UDP       0.77      0.71      0.74      3871\n",
            "      UDPLag       0.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.91     25000\n",
            "   macro avg       0.65      0.53      0.57     25000\n",
            "weighted avg       0.89      0.91      0.89     25000\n",
            "\n",
            "\n",
            "Stacking Before Tuning Confusion Matrix Fold 10\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     607        160        159        0         \n",
            "Syn        5220       14330      113        67        \n",
            "UDP        49         601        113        0         \n",
            "UDPLag     26         12         435        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.10      0.66      0.18       926\n",
            "         Syn       0.95      0.73      0.82     19730\n",
            "         UDP       0.82      0.83      0.83      3871\n",
            "      UDPLag       0.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.73     25000\n",
            "   macro avg       0.47      0.55      0.46     25000\n",
            "weighted avg       0.88      0.73      0.78     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Stacking Folds After Tuning Confusion Matrix\n",
        "prev_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  fold_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[5] + \" fold\" + str(fold_of+1) + \".sav\"\n",
        "  fold_model = pickle.load(open(fold_model_name, \"rb\"))\n",
        "  y_pred_fold = fold_model.predict(x_test)\n",
        "  y_pred_fold = np.reshape(y_pred_fold, (-1,1))\n",
        "  print(\"\")\n",
        "  print(\"Stacking After Tuning Confusion Matrix Fold \" + str(fold_of+1))\n",
        "  y_pred_fold = label_encoder.inverse_transform(y_pred_fold)\n",
        "  fold_cf = confusion_matrix(y_test, y_pred_fold, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',fold_cf[0][0],fold_cf[0][1],fold_cf[0][2],fold_cf[0][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',fold_cf[1][0],fold_cf[1][1],fold_cf[1][2],fold_cf[1][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',fold_cf[2][0],fold_cf[2][1],fold_cf[1][2],fold_cf[2][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',fold_cf[3][0],fold_cf[3][1],fold_cf[3][2],fold_cf[3][3]))\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred_fold, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynbzs4rwNgcB",
        "outputId": "5abdcdd7-e5a0-44d2-c807-0c574abdbca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 1\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     777        148        1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     16         27         430        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.97      0.84      0.90       926\n",
            "         Syn       0.99      1.00      0.99     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.97     25000\n",
            "   macro avg       0.97      0.71      0.71     25000\n",
            "weighted avg       0.98      0.97      0.96     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     727        198        1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     16         27         430        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.97      0.79      0.87       926\n",
            "         Syn       0.99      1.00      0.99     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.97     25000\n",
            "   macro avg       0.96      0.69      0.70     25000\n",
            "weighted avg       0.97      0.97      0.96     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     495        430        1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     16         28         429        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.96      0.53      0.69       926\n",
            "         Syn       0.98      1.00      0.99     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.96      0.63      0.65     25000\n",
            "weighted avg       0.96      0.96      0.95     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     751        174        1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     16         28         429        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.97      0.81      0.88       926\n",
            "         Syn       0.99      1.00      0.99     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.97     25000\n",
            "   macro avg       0.96      0.70      0.71     25000\n",
            "weighted avg       0.97      0.97      0.96     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     601        321        4          0         \n",
            "Syn        1          19717      12         0         \n",
            "UDP        6          12         12         0         \n",
            "UDPLag     16         28         429        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.96      0.65      0.78       926\n",
            "         Syn       0.98      1.00      0.99     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.97     25000\n",
            "   macro avg       0.96      0.66      0.68     25000\n",
            "weighted avg       0.97      0.97      0.96     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 6\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     827        98         1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     16         28         429        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.98      0.89      0.93       926\n",
            "         Syn       0.99      1.00      1.00     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.97      0.72      0.72     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     856        70         0          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        7          11         12         0         \n",
            "UDPLag     22         22         429        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.97      0.92      0.95       926\n",
            "         Syn       0.99      1.00      1.00     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.73      0.72     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     842        83         1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     16         28         429        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.98      0.91      0.94       926\n",
            "         Syn       0.99      1.00      1.00     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.97      0.73      0.72     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     810        115        1          0         \n",
            "Syn        1          19717      12         0         \n",
            "UDP        6          12         12         0         \n",
            "UDPLag     16         27         430        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.97      0.87      0.92       926\n",
            "         Syn       0.99      1.00      1.00     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.97      0.72      0.72     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Stacking After Tuning Confusion Matrix Fold 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     833        92         1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     17         27         429        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.97      0.90      0.94       926\n",
            "         Syn       0.99      1.00      1.00     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.97      0.72      0.72     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Folds Before Tuning Confusion Matrix\n",
        "prev_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  fold_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[0] + \" fold\" + str(fold_of+1) + \".sav\"\n",
        "  fold_model = pickle.load(open(fold_model_name, \"rb\"))\n",
        "  y_pred_fold = fold_model.predict(x_test)\n",
        "  y_pred_fold = np.reshape(y_pred_fold, (-1,1))\n",
        "  print(\"\")\n",
        "  print(\"Random Forest Before Tuning Confusion Matrix Fold \" + str(fold_of+1))\n",
        "  y_pred_fold = label_encoder.inverse_transform(y_pred_fold)\n",
        "  fold_cf = confusion_matrix(y_test, y_pred_fold, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',fold_cf[0][0],fold_cf[0][1],fold_cf[0][2],fold_cf[0][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',fold_cf[1][0],fold_cf[1][1],fold_cf[1][2],fold_cf[1][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',fold_cf[2][0],fold_cf[2][1],fold_cf[1][2],fold_cf[2][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',fold_cf[3][0],fold_cf[3][1],fold_cf[3][2],fold_cf[3][3]))\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred_fold, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ2d4nuvGDT0",
        "outputId": "27ffd64d-e295-495e-b2cd-c53be3a3c6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 1\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        1408       18321      0          0         \n",
            "UDP        20         0          0          0         \n",
            "UDPLag     38         0          9          414       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.40      1.00      0.57       988\n",
            "         Syn       1.00      0.93      0.96     19729\n",
            "         UDP       1.00      0.99      1.00      3822\n",
            "      UDPLag       1.00      0.90      0.95       461\n",
            "\n",
            "    accuracy                           0.94     25000\n",
            "   macro avg       0.85      0.96      0.87     25000\n",
            "weighted avg       0.98      0.94      0.95     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 2\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        15         19699      6          9         \n",
            "UDP        20         0          6          0         \n",
            "UDPLag     38         0          34         389       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.93      1.00      0.96       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.99      0.99      0.99      3822\n",
            "      UDPLag       0.98      0.84      0.91       461\n",
            "\n",
            "    accuracy                           1.00     25000\n",
            "   macro avg       0.97      0.96      0.97     25000\n",
            "weighted avg       1.00      1.00      1.00     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        926        18803      0          0         \n",
            "UDP        20         0          0          0         \n",
            "UDPLag     38         0          0          423       \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.50      1.00      0.67       988\n",
            "         Syn       1.00      0.95      0.98     19729\n",
            "         UDP       1.00      0.99      1.00      3822\n",
            "      UDPLag       1.00      0.92      0.96       461\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.88      0.97      0.90     25000\n",
            "weighted avg       0.98      0.96      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 4\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     985        0          3          0         \n",
            "Syn        2          19712      15         0         \n",
            "UDP        18         2          15         0         \n",
            "UDPLag     34         4          63         360       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      1.00      0.97       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.98      0.99      0.99      3822\n",
            "      UDPLag       1.00      0.78      0.88       461\n",
            "\n",
            "    accuracy                           0.99     25000\n",
            "   macro avg       0.98      0.94      0.96     25000\n",
            "weighted avg       0.99      0.99      0.99     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        49         19668      11         1         \n",
            "UDP        17         2          11         0         \n",
            "UDPLag     38         0          5          418       \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.90      1.00      0.95       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       1.00      1.00      1.00      3822\n",
            "      UDPLag       1.00      0.91      0.95       461\n",
            "\n",
            "    accuracy                           1.00     25000\n",
            "   macro avg       0.97      0.97      0.97     25000\n",
            "weighted avg       1.00      1.00      1.00     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 6\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        889        18825      15         0         \n",
            "UDP        20         0          15         0         \n",
            "UDPLag     38         0          63         360       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.51      1.00      0.68       988\n",
            "         Syn       1.00      0.95      0.98     19729\n",
            "         UDP       0.98      0.99      0.99      3822\n",
            "      UDPLag       1.00      0.78      0.88       461\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.87      0.93      0.88     25000\n",
            "weighted avg       0.98      0.96      0.96     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 7\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     986        0          2          0         \n",
            "Syn        959        18770      0          0         \n",
            "UDP        20         0          0          0         \n",
            "UDPLag     38         0          0          423       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.49      1.00      0.66       988\n",
            "         Syn       1.00      0.95      0.98     19729\n",
            "         UDP       1.00      0.99      1.00      3822\n",
            "      UDPLag       1.00      0.92      0.96       461\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.87      0.97      0.90     25000\n",
            "weighted avg       0.98      0.96      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 8\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        1408       18321      0          0         \n",
            "UDP        20         0          0          0         \n",
            "UDPLag     38         0          107        316       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.40      1.00      0.57       988\n",
            "         Syn       1.00      0.93      0.96     19729\n",
            "         UDP       0.97      0.99      0.98      3822\n",
            "      UDPLag       1.00      0.69      0.81       461\n",
            "\n",
            "    accuracy                           0.94     25000\n",
            "   macro avg       0.84      0.90      0.83     25000\n",
            "weighted avg       0.97      0.94      0.95     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 9\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        934        18795      0          0         \n",
            "UDP        20         0          0          0         \n",
            "UDPLag     38         0          34         389       \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.50      1.00      0.67       988\n",
            "         Syn       1.00      0.95      0.98     19729\n",
            "         UDP       0.99      0.99      0.99      3822\n",
            "      UDPLag       1.00      0.84      0.92       461\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.87      0.95      0.89     25000\n",
            "weighted avg       0.98      0.96      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest Before Tuning Confusion Matrix Fold 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        941        18773      15         0         \n",
            "UDP        20         0          15         0         \n",
            "UDPLag     38         0          33         390       \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.50      1.00      0.66       988\n",
            "         Syn       1.00      0.95      0.98     19729\n",
            "         UDP       0.99      0.99      0.99      3822\n",
            "      UDPLag       1.00      0.85      0.92       461\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.87      0.95      0.89     25000\n",
            "weighted avg       0.98      0.96      0.96     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Folds After Tuning Confusion Matrix\n",
        "prev_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  fold_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[1] + \" fold\" + str(fold_of+1) + \".sav\"\n",
        "  fold_model = pickle.load(open(fold_model_name, \"rb\"))\n",
        "  y_pred_fold = fold_model.predict(x_test)\n",
        "  y_pred_fold = np.reshape(y_pred_fold, (-1,1))\n",
        "  print(\"\")\n",
        "  print(\"Random Forest After Tuning Confusion Matrix Fold \" + str(fold_of+1))\n",
        "  y_pred_fold = label_encoder.inverse_transform(y_pred_fold)\n",
        "  fold_cf = confusion_matrix(y_test, y_pred_fold, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',fold_cf[0][0],fold_cf[0][1],fold_cf[0][2],fold_cf[0][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',fold_cf[1][0],fold_cf[1][1],fold_cf[1][2],fold_cf[1][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',fold_cf[2][0],fold_cf[2][1],fold_cf[1][2],fold_cf[2][3]))\n",
        "  print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',fold_cf[3][0],fold_cf[3][1],fold_cf[3][2],fold_cf[3][3]))\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred_fold, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm7UpMT5MmWN",
        "outputId": "cacf766a-5d84-41d1-c458-57b7415767b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 1\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     986        2          0          0         \n",
            "Syn        0          19714      15         0         \n",
            "UDP        17         2          15         0         \n",
            "UDPLag     36         2          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      1.00      0.97       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 2\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        2          19712      15         0         \n",
            "UDP        17         2          15         0         \n",
            "UDPLag     34         4          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      1.00      0.97       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 3\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        1          19713      15         0         \n",
            "UDP        17         2          15         0         \n",
            "UDPLag     34         4          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      1.00      0.97       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     987        1          0          0         \n",
            "Syn        0          19714      15         0         \n",
            "UDP        10         10         15         0         \n",
            "UDPLag     28         10         423        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.96      1.00      0.98       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      0.99      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 5\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        227        19487      15         0         \n",
            "UDP        19         0          15         0         \n",
            "UDPLag     38         0          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.78      1.00      0.87       988\n",
            "         Syn       1.00      0.99      0.99     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.97     25000\n",
            "   macro avg       0.92      0.75      0.70     25000\n",
            "weighted avg       0.98      0.97      0.96     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 6\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     964        20         4          0         \n",
            "Syn        1          19713      15         0         \n",
            "UDP        17         2          15         0         \n",
            "UDPLag     34         4          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      0.98      0.96       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.74      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 7\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        102        19612      15         0         \n",
            "UDP        17         2          15         0         \n",
            "UDPLag     34         4          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.87      1.00      0.93       988\n",
            "         Syn       1.00      0.99      1.00     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.94      0.75      0.72     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        2          19712      15         0         \n",
            "UDP        18         2          15         0         \n",
            "UDPLag     34         4          423        0         \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      1.00      0.97       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      0.99      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 9\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        1          19713      15         0         \n",
            "UDP        16         3          15         0         \n",
            "UDPLag     33         5          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      1.00      0.98       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n",
            "\n",
            "Random Forest After Tuning Confusion Matrix Fold 10\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     988        0          0          0         \n",
            "Syn        1          19713      15         0         \n",
            "UDP        17         2          15         0         \n",
            "UDPLag     34         4          423        0         \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.95      1.00      0.97       988\n",
            "         Syn       1.00      1.00      1.00     19729\n",
            "         UDP       0.90      1.00      0.94      3822\n",
            "      UDPLag       1.00      0.00      0.00       461\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf_ejsiX_FOS",
        "outputId": "15b691c7-2724-4c8e-da43-17afaf25ed15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaboost Before Tuning best model is fold number 1 with accuracy of 0.91628\n",
            "\n",
            "Confusion matrix\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     404        169        308        45        \n",
            "Syn        12         19330      326        62        \n",
            "UDP        16         687        326        0         \n",
            "UDPLag     20         9          439        5         \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.89      0.44      0.59       926\n",
            "         Syn       0.96      0.98      0.97     19730\n",
            "         UDP       0.75      0.82      0.78      3871\n",
            "      UDPLag       0.04      0.01      0.02       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.66      0.56      0.59     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Adaboost before tuning model with best accuracy\n",
        "fold_with_best_scores = 0\n",
        "prev_fold = 0\n",
        "best_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  if (result_adaboost_beforetuning_data[fold_of]['accuracy'] > result_randomforest_beforetuning_data[prev_fold]['accuracy']):\n",
        "    best_fold = fold_of\n",
        "  prev_fold = fold_of\n",
        "print(\"Adaboost Before Tuning best model is fold number \" + str(best_fold+1) + \" with accuracy of \" + str(result_adaboost_beforetuning_data[best_fold]['accuracy']))\n",
        "best_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[2] + \" fold\" + str(best_fold+1) + \".sav\"\n",
        "best_model = pickle.load(open(best_model_name, \"rb\"))\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[2] + \" best model\"+\".sav\"\n",
        "pickle.dump(best_model, open(filename, 'wb'))\n",
        "\n",
        "y_pred_best_model = best_model.predict(x_test)\n",
        "y_pred_best_model = np.reshape(y_pred_best_model,(-1,1))\n",
        "print(\"\")\n",
        "print(\"Confusion matrix\")\n",
        "y_pred_best_model = label_encoder.inverse_transform(y_pred_best_model)\n",
        "bmcf = confusion_matrix(y_test, y_pred_best_model, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])   #best model confusion matrix\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',bmcf[0][0],bmcf[0][1],bmcf[0][2],bmcf[0][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',bmcf[1][0],bmcf[1][1],bmcf[1][2],bmcf[1][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',bmcf[2][0],bmcf[2][1],bmcf[1][2],bmcf[2][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',bmcf[3][0],bmcf[3][1],bmcf[3][2],bmcf[3][3]))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_best_model, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7UkEzkDD3hg",
        "outputId": "a5f93e01-a0b3-4534-f5af-9bd7c543a2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaboost After Tuning best model is fold number 9 with accuracy of 0.96056\n",
            "\n",
            "Confusion matrix\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     587        300        37         2         \n",
            "Syn        14         19573      135        8         \n",
            "UDP        6          5          135        56        \n",
            "UDPLag     17         16         390        50        \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.94      0.63      0.76       926\n",
            "         Syn       0.98      0.99      0.99     19730\n",
            "         UDP       0.87      0.98      0.92      3871\n",
            "      UDPLag       0.43      0.11      0.17       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.81      0.68      0.71     25000\n",
            "weighted avg       0.95      0.96      0.95     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Adaboost after tuning model with best accuracy\n",
        "fold_with_best_scores = 0\n",
        "prev_fold = 0\n",
        "best_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  if (result_adaboost_aftertuning_data[fold_of]['accuracy'] > result_randomforest_aftertuning_data[prev_fold]['accuracy']):\n",
        "    best_fold = fold_of\n",
        "  prev_fold = fold_of\n",
        "print(\"Adaboost After Tuning best model is fold number \" + str(best_fold+1) + \" with accuracy of \" + str(result_adaboost_aftertuning_data[best_fold]['accuracy']))\n",
        "best_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[3] + \" fold\" + str(best_fold+1) + \".sav\"\n",
        "best_model = pickle.load(open(best_model_name, \"rb\"))\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[3] + \" best model\"+\".sav\"\n",
        "pickle.dump(best_model, open(filename, 'wb'))\n",
        "\n",
        "y_pred_best_model = best_model.predict(x_test)\n",
        "y_pred_best_model = np.reshape(y_pred_best_model,(-1,1))\n",
        "print(\"\")\n",
        "print(\"Confusion matrix\")\n",
        "y_pred_best_model = label_encoder.inverse_transform(y_pred_best_model)\n",
        "bmcf = confusion_matrix(y_test, y_pred_best_model, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])   #best model confusion matrix\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',bmcf[0][0],bmcf[0][1],bmcf[0][2],bmcf[0][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',bmcf[1][0],bmcf[1][1],bmcf[1][2],bmcf[1][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',bmcf[2][0],bmcf[2][1],bmcf[1][2],bmcf[2][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',bmcf[3][0],bmcf[3][1],bmcf[3][2],bmcf[3][3]))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_best_model, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVkgft70DkHa",
        "outputId": "0f2c1da9-c537-4284-aad5-72e29eee9ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Before Tuning best model is fold number 1 with accuracy of 0.9218\n",
            "\n",
            "Confusion matrix\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     373        236        315        2         \n",
            "Syn        20         19336      312        62        \n",
            "UDP        7          529        312        0         \n",
            "UDPLag     20         12         440        1         \n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.89      0.40      0.55       926\n",
            "         Syn       0.96      0.98      0.97     19730\n",
            "         UDP       0.76      0.86      0.81      3871\n",
            "      UDPLag       0.02      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.92     25000\n",
            "   macro avg       0.66      0.56      0.58     25000\n",
            "weighted avg       0.91      0.92      0.91     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Stacking before tuning model with best accuracy\n",
        "fold_with_best_scores = 0\n",
        "prev_fold = 0\n",
        "best_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  if (result_stacking_beforetuning_data[fold_of]['accuracy'] > result_randomforest_beforetuning_data[prev_fold]['accuracy']):\n",
        "    best_fold = fold_of\n",
        "  prev_fold = fold_of\n",
        "print(\"Stacking Before Tuning best model is fold number \" + str(best_fold+1) + \" with accuracy of \" + str(result_stacking_beforetuning_data[best_fold]['accuracy']))\n",
        "best_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[4] + \" fold\" + str(best_fold+1) + \".sav\"\n",
        "best_model = pickle.load(open(best_model_name, \"rb\"))\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[4] + \" best model\"+\".sav\"\n",
        "pickle.dump(best_model, open(filename, 'wb'))\n",
        "\n",
        "y_pred_best_model = best_model.predict(x_test)\n",
        "y_pred_best_model = np.reshape(y_pred_best_model,(-1,1))\n",
        "print(\"\")\n",
        "print(\"Confusion matrix\")\n",
        "y_pred_best_model = label_encoder.inverse_transform(y_pred_best_model)\n",
        "bmcf = confusion_matrix(y_test, y_pred_best_model, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])   #best model confusion matrix\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',bmcf[0][0],bmcf[0][1],bmcf[0][2],bmcf[0][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',bmcf[1][0],bmcf[1][1],bmcf[1][2],bmcf[1][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',bmcf[2][0],bmcf[2][1],bmcf[1][2],bmcf[2][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',bmcf[3][0],bmcf[3][1],bmcf[3][2],bmcf[3][3]))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_best_model, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnHPkp39D63M",
        "outputId": "0ef9c692-66d9-4120-e2b8-ca8976e87a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking After Tuning best model is fold number 8 with accuracy of 0.97652\n",
            "\n",
            "Confusion matrix\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     842        83         1          0         \n",
            "Syn        0          19718      12         0         \n",
            "UDP        5          13         12         0         \n",
            "UDPLag     16         28         429        0         \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.98      0.91      0.94       926\n",
            "         Syn       0.99      1.00      1.00     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.97      0.73      0.72     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Stacking after tuning model with best accuracy\n",
        "fold_with_best_scores = 0\n",
        "prev_fold = 0\n",
        "best_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  if (result_stacking_aftertuning_data[fold_of]['accuracy'] > result_randomforest_beforetuning_data[prev_fold]['accuracy']):\n",
        "    best_fold = fold_of\n",
        "  prev_fold = fold_of\n",
        "print(\"Stacking After Tuning best model is fold number \" + str(best_fold+1) + \" with accuracy of \" + str(result_stacking_aftertuning_data[best_fold]['accuracy']))\n",
        "best_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[5] + \" fold\" + str(best_fold+1) + \".sav\"\n",
        "best_model = pickle.load(open(best_model_name, \"rb\"))\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[5] + \" best model\"+\".sav\"\n",
        "pickle.dump(best_model, open(filename, 'wb'))\n",
        "\n",
        "y_pred_best_model = best_model.predict(x_test)\n",
        "y_pred_best_model = np.reshape(y_pred_best_model,(-1,1))\n",
        "print(\"\")\n",
        "print(\"Confusion matrix\")\n",
        "y_pred_best_model = label_encoder.inverse_transform(y_pred_best_model)\n",
        "bmcf = confusion_matrix(y_test, y_pred_best_model, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])   #best model confusion matrix\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',bmcf[0][0],bmcf[0][1],bmcf[0][2],bmcf[0][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',bmcf[1][0],bmcf[1][1],bmcf[1][2],bmcf[1][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',bmcf[2][0],bmcf[2][1],bmcf[1][2],bmcf[2][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',bmcf[3][0],bmcf[3][1],bmcf[3][2],bmcf[3][3]))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_best_model, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a6IAC9k-Yj2",
        "outputId": "ad805723-a749-40f4-8b0c-ecb120a87b3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Before Tuning best model is fold number 9 with accuracy of 0.97984\n",
            "\n",
            "Confusion matrix\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     926        0          0          0         \n",
            "Syn        1          19717      12         0         \n",
            "UDP        16         2          12         0         \n",
            "UDPLag     41         4          428        0         \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.94      1.00      0.97       926\n",
            "         Syn       1.00      1.00      1.00     19730\n",
            "         UDP       0.90      1.00      0.94      3871\n",
            "      UDPLag       1.00      0.00      0.00       473\n",
            "\n",
            "    accuracy                           0.98     25000\n",
            "   macro avg       0.96      0.75      0.73     25000\n",
            "weighted avg       0.98      0.98      0.97     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Random Forest before tuning model with best accuracy\n",
        "fold_with_best_scores = 0\n",
        "prev_fold = 0\n",
        "best_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  if (result_randomforest_beforetuning_data[fold_of]['accuracy'] > result_randomforest_beforetuning_data[prev_fold]['accuracy']):\n",
        "    best_fold = fold_of\n",
        "  prev_fold = fold_of\n",
        "print(\"Random Forest Before Tuning best model is fold number \" + str(best_fold+1) + \" with accuracy of \" + str(result_randomforest_beforetuning_data[best_fold]['accuracy']))\n",
        "best_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[0] + \" fold\" + str(best_fold+1) + \".sav\"\n",
        "best_model = pickle.load(open(best_model_name, \"rb\"))\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[0] + \" best model\"+\".sav\"\n",
        "pickle.dump(best_model, open(filename, 'wb'))\n",
        "\n",
        "y_pred_best_model = best_model.predict(x_test)\n",
        "y_pred_best_model = np.reshape(y_pred_best_model,(-1,1))\n",
        "print(\"\")\n",
        "print(\"Confusion matrix\")\n",
        "y_pred_best_model = label_encoder.inverse_transform(y_pred_best_model)\n",
        "bmcf = confusion_matrix(y_test, y_pred_best_model, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])   #best model confusion matrix\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',bmcf[0][0],bmcf[0][1],bmcf[0][2],bmcf[0][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',bmcf[1][0],bmcf[1][1],bmcf[1][2],bmcf[1][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',bmcf[2][0],bmcf[2][1],bmcf[1][2],bmcf[2][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',bmcf[3][0],bmcf[3][1],bmcf[3][2],bmcf[3][3]))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_best_model, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1W2unj9Dv24",
        "outputId": "02c5f6cd-724b-4f1d-e881-7282dfb22afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest After Tuning best model is fold number 9 with accuracy of 0.95932\n",
            "\n",
            "Confusion matrix\n",
            "           BENIGN     Syn        UDP        UDPLag    \n",
            "BENIGN     926        0          0          0         \n",
            "Syn        921        18809      0          0         \n",
            "UDP        19         0          0          0         \n",
            "UDPLag     45         0          32         396       \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:154: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.48      1.00      0.65       926\n",
            "         Syn       1.00      0.95      0.98     19730\n",
            "         UDP       0.99      1.00      0.99      3871\n",
            "      UDPLag       1.00      0.84      0.91       473\n",
            "\n",
            "    accuracy                           0.96     25000\n",
            "   macro avg       0.87      0.95      0.88     25000\n",
            "weighted avg       0.98      0.96      0.97     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Random Forest after tuning model with best accuracy\n",
        "fold_with_best_scores = 0\n",
        "prev_fold = 0\n",
        "best_fold = 0\n",
        "for fold_of in range(total_fold):\n",
        "  if (result_randomforest_aftertuning_data[fold_of]['accuracy'] > result_randomforest_aftertuning_data[prev_fold]['accuracy']):\n",
        "    best_fold = fold_of\n",
        "  prev_fold = fold_of\n",
        "print(\"Random Forest After Tuning best model is fold number \" + str(best_fold+1) + \" with accuracy of \" + str(result_randomforest_aftertuning_data[best_fold]['accuracy']))\n",
        "best_model_name = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[1] + \" fold\" + str(best_fold+1) + \".sav\"\n",
        "best_model = pickle.load(open(best_model_name, \"rb\"))\n",
        "filename = \"drive/MyDrive/Dataset/SavedModels/\"+ classifiers_name[1] + \" best model\"+\".sav\"\n",
        "pickle.dump(best_model, open(filename, 'wb'))\n",
        "\n",
        "y_pred_best_model = best_model.predict(x_test)\n",
        "y_pred_best_model = np.reshape(y_pred_best_model,(-1,1))\n",
        "print(\"\")\n",
        "print(\"Confusion matrix\")\n",
        "y_pred_best_model = label_encoder.inverse_transform(y_pred_best_model)\n",
        "bmcf = confusion_matrix(y_test, y_pred_best_model, labels=[\"BENIGN\", \"Syn\", \"UDP\", \"UDPLag\"])   #best model confusion matrix\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('','BENIGN','Syn','UDP','UDPLag'))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('BENIGN',bmcf[0][0],bmcf[0][1],bmcf[0][2],bmcf[0][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('Syn',bmcf[1][0],bmcf[1][1],bmcf[1][2],bmcf[1][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDP',bmcf[2][0],bmcf[2][1],bmcf[1][2],bmcf[2][3]))\n",
        "print (\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format('UDPLag',bmcf[3][0],bmcf[3][1],bmcf[3][2],bmcf[3][3]))\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_best_model, zero_division=1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}